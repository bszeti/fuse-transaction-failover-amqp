= Test Artemis broker failover with Fuse and Qpid JMS

This example tests an HA broker failover while a Fuse application actively receives and sends messags to the broker.
On the client side we use the Qpid JMS client for Artemis AMQP endpoint.

[NOTE]
====
TL;DR: An issue was identified with the Qpid JMS AMQP client related to transactional failovers. It's fixed in version 0.55.0.
====

To run the example we need Apache Artemis donwloaded and set its path in the `activemq.basedir` propety for Maven. For example:

`export ARTEMIS_HOME=/Users/bszeti/tools/amq-broker-7.7.0`

Then we can run the test - with sending the log into `out.log` - like this (see `run.sh`):
```
export "MAVEN_OPTS=-Dorg.slf4j.simpleLogger.log.bszeti.artemis.test=info"
export "MAVEN_OPTS=$MAVEN_OPTS -Dorg.slf4j.simpleLogger.showDateTime=true -Dorg.slf4j.simpleLogger.showThreadName=true"
export "MAVEN_OPTS=$MAVEN_OPTS -Dorg.slf4j.simpleLogger.logFile=out.log"
mvn clean install -Dactivemq.basedir=$ARTEMIS_HOME
```

[NOTE]
====
Sending all the logs to stdout looks messy, logging to `out.log` was just a quick workaround and it's beneficial when debug/trace is enabled.
====

The application is a simple JMS bridge that moves messages from a "source" queue to a "target" queue in a transacted way. The goal would be to achieve a seamless failover without lost or extra messages.

Steps:

- Two broker instances are started in HA mode with shared storage. The brokers' `max-delivery-attempts` is 7.
- The application uses the Qpid JMS AMQP client with the following connection string:

  failover:(amqp://localhost:61616,amqp://localhost:61617)?failover.maxReconnectAttempts=16&jms.prefetchPolicy.all=5&jms.forceSyncSend=true

- `org.messaginghub:pooled-jms` connection pool is used with 1 connection.
- First we send messages to our "source" queue (see property `send.count`),
- A unique `UUID` header is added to all messages. These are added later as `_AMQ_DUPL_ID` header when they are sent to the target queue to utilize Artemis Duplicate Detection.
- Then the JMS consumers (`receive.concurrentConsumers`) are started.
- Messages are consumed transacted and sent to a `target` queue.
- After 10% of the messages the broker failover is triggered. The JMS clients automatically reconnect to process the rest of the messages.
- The application is shut down when no more messages are received from `source`. Before that messages are counted on the queues.

Expected outcome:
- All the messages are moved to the `target` queue without message loss or duplicates.

See `application.properties` for parameters:

.application.properties
[options="header",width="100%",align="center"]
|===
|Parameter |Example | Notes
|connection.type              |AMQP or CORE|ConnectionFactory type
|connection.remoteUrl         |         |Connection string to broker - must match type
|connection.maxConnections    |1        |Pool size
|send.count                   |1000     |Message count
|send.enabled                 |true     |Send messages to `source` queue
|send.message                 |#{'$'}{header.UUID} - #{'$'}{header.SEND_COUNTER}|Exception is thrown if it contains `error`
|transaction.mode             |NO_TRANSACTION_MANAGER or LAZY_TRANSACTION_MANAGER or TRANSACTION_MANAGER_WITH_PROPAGATION| See modes below
|receive.enabled              |true     |Receive messages from source queue
|receive.concurrentConsumers  |20       |Consumers
|receive.forwardEnable        |true     |Forward messaged to `target` queue
|receive.addAmqDuplId         |true     |Add _AMQ_DUPL_ID header
|receive.delayBeforeForward   |0        |Optional delay (ms)
|receive.delayBeforeDone      |0        |Optional delay (ms)
|receive.cacheLevel           |CACHE_NONE or CACHE_CONSUMER|
|receive.brokerFailover       |true     |Do broker failover during test
|shutDownDelay                |10000    |Wait before shutdown (ms)
|===


See summary output of the application:
```
25784 [main] [INFO] TransactionFailoverFuse - Message count before listener start - sent: 1000, received: 0, forwarded: 0
28649 [main] [INFO] TransactionFailoverFuse - Message count after failover - sent: 1000, received: 111, forwarded: 111
50651 [main] [INFO] TransactionFailoverFuse - Message count at the end - sent: 1000, received: 1000, forwarded: 1000
50651 [main] [INFO] TransactionFailoverFuse - Message count on source queue: 0
50651 [main] [INFO] TransactionFailoverFuse - Message count on target queue: 999
50651 [main] [WARNING] TransactionFailoverFuse - Message count on DLQ queue: 0
```

The missing or DLQ message ids are also logged with their UUID and order number:
```
34658 [main] [INFO] TransactionFailoverFuse - Message in DLQ: 5e213243-d579-4db7-9ef3-a5233e3fad63 - 128
34658 [main] [INFO] TransactionFailoverFuse - Message missing:: bd1ec840-909d-41db-a51a-e160d83a09b5 - 129
```

The example application creates and starts two Artemis server instances by default under `target/server0` and `target/server1` directories. Use the _noServer_ Maven profile (`mvn -PnoSever clean install`) to skip this, so you need to start one or two a broker instances yourself.

== Different scenarios to try

Different issues were found with different settings. A fix applied in Qpid JMS client version 0.55.0 solved the "Masseges on DLQ with AMQP" problem.
The other issue - message loss - is probably related to Spring JMS (scenario _Auto-created TransactionManager with caching_) and it may still be valid.

[NOTE]
====
The issues described below are adhoc - based on when exactly the broker failover happens - and the test should be run several times to observe or validate.
====

=== No Transaction Manager - `lazyCreateTransactionManager=false`
```
transaction.mode = NO_TRANSACTION_MANAGER
receive.cacheLevel = CACHE_CONSUMER
```
Notes:

* No TransactionManager is used. Transactions are managed by Spring's `DefaultMessageListenerContainer`
* Receive: A transacted JMS session is created and cached by DefaultMessageListenerContainer.
* Send: Send is using the same session and transaction as receive.

Outcome:

* Masseges on DLQ with AMQP. Messages are redelivered despite they were already sent to target queue (see https://issues.redhat.com/browse/ENTMQCL-2339). Because of transacted send the duplicate exception reaches the client and causes message redelivery until _max-delivery-attempts_ is reached and the broker drops the message on the DLQ. (see https://issues.redhat.com/browse/ENTMQBR-4235)
* Sometimes the test execution takes much longer, it had to wait for transaction timeouts on the broker side probably
* Works with `qpid-jms-client:0.55.0` or with CORE protocol.

=== Auto-created TransactionManager without caching
```
transaction.mode = LAZY_TRANSACTION_MANAGER
receive.cacheLevel = CACHE_NONE
```

Notes:

* A TransactionManager is created and used automatically
* Receive: The new transacted JMS session is created by TransactionManager for each message.
* Send: Send uses the same session and transaction as receive

Outcome:

* Messages on DLQ messages with AMQP. Less, but similar than in the previous scenario.
* Slower as there is no caching
* Works with `qpid-jms-client:0.55.0` or with CORE protocol.


=== Auto-created TransactionManager with caching
```
transaction.mode = LAZY_TRANSACTION_MANAGER
receive.cacheLevel = CACHE_CONSUMER
```

Notes:

* A TransactionManager is created and used automatically
* Consumers are cached to increase performance
* Receive: A JMS session is created and cached by DefaultMessageListenerContainer for all receives.
* Send: Another (transacted) JMS session from the TransactionManager is used. So the send and receive is not done in the same JMS session - nor in the same transaction

Outcome:

* Message loss during failover with AMQP
* Message loss was observed both with AMQP and CORE protocol

=== TransactionManager with non-transacted send
```
transaction.mode = TRANSACTION_MANAGER_WITH_PROPAGATION
receive.cacheLevel = CACHE_CONSUMER
transaction.propagation = PROPAGATION_NOT_SUPPORTED
```

Notes:

* Manually created TransactionManager
* TransactionPolicy is created with `PROPAGATION_NOT_SUPPORTED` so the send doesn't participate in the transaction.
* With `PROPAGATION_REQUIRED` this matched the previous scenario

Outcome:

* No message loss, no DLQ messages
* Message duplicates do happen, but they are silently ignored by the broker, so it's fine.
* No duplicates with `qpid-jms-client:0.55.0` or with CORE protocol.

=== SJMS with transacted send
```
transaction.mode = SJMS
```

Notes:

* Using a non-pooled connection factory, the component takes care of that
* Receive and send is in the same transaction.

Outcome:

* DLQ messages caused by duplicates with AMQP
* Works with `qpid-jms-client:0.55.0` or with CORE protocol.
* Another workaround is to have non-transacted send (simply use `transacted=false` on send)

== Summary

The Qpid JMS client had an issue - before version 0.55.0 - that causes duplicates during broker failover (in case of transacted receive and send) - https://issues.redhat.com/browse/ENTMQCL-2339.
If we have to use AMQP, then we need to make sure that the _send_ is non-transacted to avoid these duplicates causing an exception on the client side and eventually messages on DLQ - https://issues.redhat.com/browse/ENTMQBR-4235.

The _camel-jms_ component with `CACHE_CONSUMER` enabled doing transacted receive and send - with a TransactionManager - seems to loose messages both with AMQP and CORE ConnectionFactory.
The _camel-sjms_ component works fine, so best setup is probably to use _camel-sjms_ with _CORE_ protocol.
